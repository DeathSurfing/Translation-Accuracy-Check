{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading averaged_perceptron_tagger...\n",
      "Downloading universal_tagset...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading averaged_perceptron_tagger...\n",
      "Downloading universal_tagset...\n",
      "Warning: Using simple tokenization due to NLTK error: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - '/Users/vikk/nltk_data'\n",
      "    - '/Library/Frameworks/Python.framework/Versions/3.12/nltk_data'\n",
      "    - '/Library/Frameworks/Python.framework/Versions/3.12/share/nltk_data'\n",
      "    - '/Library/Frameworks/Python.framework/Versions/3.12/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Error in METEOR score calculation: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): मैं कल मुंबई जाऊंगा\n",
      "\n",
      "Detailed Scores:\n",
      "BLEU Score (Direct): 0.0000\n",
      "METEOR Score (Direct): 0.0000\n",
      "BERT Similarity (Direct): 0.2289\n",
      "\n",
      "Aggregate Quality Score: 0.0763\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def ensure_nltk_resources():\n",
    "    \"\"\"\n",
    "    Download all required NLTK resources.\n",
    "    Returns True if successful, False if any download fails.\n",
    "    \"\"\"\n",
    "    required_resources = [\n",
    "        'punkt',\n",
    "        'wordnet',\n",
    "        'omw-1.4',\n",
    "        'averaged_perceptron_tagger',\n",
    "        'universal_tagset'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        for resource in required_resources:\n",
    "            try:\n",
    "                nltk.data.find(f'tokenizers/{resource}')\n",
    "            except LookupError:\n",
    "                print(f\"Downloading {resource}...\")\n",
    "                nltk.download(resource, quiet=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading NLTK resources: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def calculate_bleu_score(reference, candidate):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score between reference and candidate texts with improved tokenization.\n",
    "    \"\"\"\n",
    "    if not reference or not candidate:\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Convert to lowercase and tokenize\n",
    "        reference = reference.lower().strip()\n",
    "        candidate = candidate.lower().strip()\n",
    "        \n",
    "        # Use word_tokenize instead of punkt directly\n",
    "        reference_tokens = [reference.split()]  # Simple word splitting as fallback\n",
    "        candidate_tokens = candidate.split()\n",
    "        \n",
    "        try:\n",
    "            # Try NLTK tokenization if available\n",
    "            reference_tokens = [nltk.word_tokenize(reference)]\n",
    "            candidate_tokens = nltk.word_tokenize(candidate)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Using simple tokenization due to NLTK error: {str(e)}\")\n",
    "        \n",
    "        # Calculate BLEU score with smoothing\n",
    "        weights = (0.25, 0.25, 0.25, 0.25)  # Equal weights for 1-4 grams\n",
    "        return sentence_bleu(reference_tokens, candidate_tokens, weights=weights)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in BLEU score calculation: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_meteor_score(reference, candidate):\n",
    "    \"\"\"Calculate METEOR score with improved error handling.\"\"\"\n",
    "    if not reference or not candidate:\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Convert to lowercase and ensure proper string format\n",
    "        reference = str(reference).lower().strip()\n",
    "        candidate = str(candidate).lower().strip()\n",
    "        \n",
    "        return meteor_score([reference], candidate)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in METEOR score calculation: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def evaluate_translation(source_text, human_translation, target_lang=\"hi\"):\n",
    "    \"\"\"\n",
    "    Evaluate translation quality using multiple metrics.\n",
    "    \"\"\"\n",
    "    # Ensure NLTK resources are available\n",
    "    if not ensure_nltk_resources():\n",
    "        raise ValueError(\"Failed to download required NLTK resources\")\n",
    "\n",
    "    if not source_text or not human_translation:\n",
    "        raise ValueError(\"Source text and human translation cannot be empty\")\n",
    "\n",
    "    try:\n",
    "        bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load BERT model: {str(e)}\")\n",
    "\n",
    "    # Calculate scores\n",
    "    scores = {\n",
    "        \"BLEU Score (Direct)\": calculate_bleu_score(source_text, human_translation),\n",
    "        \"METEOR Score (Direct)\": calculate_meteor_score(source_text, human_translation),\n",
    "        \"BERT Similarity (Direct)\": calculate_bert_similarity(source_text, human_translation, bert_model)\n",
    "    }\n",
    "\n",
    "    # Calculate aggregate score from valid scores only\n",
    "    valid_scores = [score for score in scores.values() if score is not None and score >= 0]\n",
    "    aggregate_score = np.mean(valid_scores) if valid_scores else 0.0\n",
    "\n",
    "    return scores, aggregate_score\n",
    "\n",
    "def calculate_bert_similarity(text1, text2, model):\n",
    "    \"\"\"Calculate BERT-based similarity between two texts.\"\"\"\n",
    "    if not text1 or not text2:\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Ensure texts are strings and properly formatted\n",
    "        text1 = str(text1).strip()\n",
    "        text2 = str(text2).strip()\n",
    "        \n",
    "        embeddings = model.encode([text1, text2])\n",
    "        return float(cosine_similarity([embeddings[0]], [embeddings[1]])[0, 0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error in BERT similarity calculation: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    source_text = \"I'll go to Mumbai tomorrow\"\n",
    "    human_translation = \"मैं कल मुंबई जाऊंगा\"\n",
    "    \n",
    "    try:\n",
    "        # First ensure all NLTK resources are available\n",
    "        if not ensure_nltk_resources():\n",
    "            print(\"Failed to initialize NLTK resources. Please check your internet connection and try again.\")\n",
    "            exit(1)\n",
    "            \n",
    "        scores, aggregate_score = evaluate_translation(source_text, human_translation)\n",
    "        \n",
    "        print(\"\\nDetailed Scores:\")\n",
    "        for metric, score in scores.items():\n",
    "            print(f\"{metric}: {score:.4f}\")\n",
    "        \n",
    "        print(f\"\\nAggregate Quality Score: {aggregate_score:.4f}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Evaluation Error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

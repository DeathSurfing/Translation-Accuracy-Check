{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing machine translation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation..............\n",
      "\n",
      "Machine Translation: मैंले कल मुंबई जाऊंगा.\n",
      "\n",
      "Evaluating translations...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading averaged_perceptron_tagger...\n",
      "Downloading universal_tagset...\n",
      "\n",
      "Human Translation Scores:\n",
      "BLEU Score: 0.0000\n",
      "METEOR Score: 0.0000\n",
      "BERT Similarity: 0.2289\n",
      "Aggregate Quality Score: 0.0763\n",
      "\n",
      "Machine Translation Scores:\n",
      "BLEU Score: 0.0000\n",
      "METEOR Score: 0.0000\n",
      "BERT Similarity: 0.2262\n",
      "Aggregate Quality Score: 0.0754\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import transformers\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "@dataclass\n",
    "class TranslationScores:\n",
    "    bleu: float\n",
    "    meteor: float\n",
    "    bert_similarity: float\n",
    "    aggregate: float\n",
    "\n",
    "class NLTKResourceManager:\n",
    "    REQUIRED_RESOURCES = [\n",
    "        'punkt',\n",
    "        'wordnet',\n",
    "        'omw-1.4',\n",
    "        'averaged_perceptron_tagger',\n",
    "        'universal_tagset'\n",
    "    ]\n",
    "\n",
    "    @classmethod\n",
    "    def ensure_resources(cls) -> bool:\n",
    "        \"\"\"Download required NLTK resources if not present.\"\"\"\n",
    "        try:\n",
    "            for resource in cls.REQUIRED_RESOURCES:\n",
    "                try:\n",
    "                    nltk.data.find(f'tokenizers/{resource}')\n",
    "                except LookupError:\n",
    "                    print(f\"Downloading {resource}...\")\n",
    "                    nltk.download(resource, quiet=True)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading NLTK resources: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "class TranslationMetrics:\n",
    "    def __init__(self):\n",
    "        self.bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def calculate_bleu(self, reference: str, candidate: str) -> float:\n",
    "        \"\"\"Calculate BLEU score between reference and candidate texts.\"\"\"\n",
    "        if not reference or not candidate:\n",
    "            return 0.0\n",
    "        try:\n",
    "            reference = reference.lower().strip()\n",
    "            candidate = candidate.lower().strip()\n",
    "            \n",
    "            try:\n",
    "                reference_tokens = [nltk.word_tokenize(reference)]\n",
    "                candidate_tokens = nltk.word_tokenize(candidate)\n",
    "            except Exception:\n",
    "                reference_tokens = [reference.split()]\n",
    "                candidate_tokens = candidate.split()\n",
    "            \n",
    "            weights = (0.25, 0.25, 0.25, 0.25)\n",
    "            return sentence_bleu(reference_tokens, candidate_tokens, weights=weights)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BLEU calculation: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def calculate_meteor(self, reference: str, candidate: str) -> float:\n",
    "        \"\"\"Calculate METEOR score between reference and candidate texts.\"\"\"\n",
    "        try:\n",
    "            reference_tokens = nltk.word_tokenize(reference)\n",
    "            candidate_tokens = nltk.word_tokenize(candidate)\n",
    "            return meteor_score([reference_tokens], candidate_tokens)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in METEOR calculation: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def calculate_bert_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Calculate BERT-based similarity between two texts.\"\"\"\n",
    "        if not text1 or not text2:\n",
    "            return 0.0\n",
    "        try:\n",
    "            text1, text2 = str(text1).strip(), str(text2).strip()\n",
    "            embeddings = self.bert_model.encode([text1, text2])\n",
    "            return float(cosine_similarity([embeddings[0]], [embeddings[1]])[0, 0])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BERT similarity calculation: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "class TranslationEvaluator:\n",
    "    def __init__(self):\n",
    "        if not NLTKResourceManager.ensure_resources():\n",
    "            raise RuntimeError(\"Failed to initialize NLTK resources\")\n",
    "        self.metrics = TranslationMetrics()\n",
    "\n",
    "    def evaluate_translation(self, source_text: str, human_translation: str) -> TranslationScores:\n",
    "        \"\"\"Evaluate translation quality using multiple metrics.\"\"\"\n",
    "        if not source_text or not human_translation:\n",
    "            raise ValueError(\"Source text and human translation cannot be empty\")\n",
    "\n",
    "        scores = TranslationScores(\n",
    "            bleu=self.metrics.calculate_bleu(source_text, human_translation),\n",
    "            meteor=self.metrics.calculate_meteor(source_text, human_translation),\n",
    "            bert_similarity=self.metrics.calculate_bert_similarity(source_text, human_translation),\n",
    "            aggregate=0.0\n",
    "        )\n",
    "\n",
    "        valid_scores = [score for score in [scores.bleu, scores.meteor, scores.bert_similarity] \n",
    "                       if score is not None and score >= 0]\n",
    "        scores.aggregate = np.mean(valid_scores) if valid_scores else 0.0\n",
    "\n",
    "        return scores\n",
    "\n",
    "class OllamaTranslator:\n",
    "    OLLAMA_API_URL = \"http://localhost:11434\"\n",
    "    DEFAULT_TIMEOUT = 300  # 5 minutes timeout for longer translations\n",
    "\n",
    "    @classmethod\n",
    "    def check_status(cls) -> bool:\n",
    "        \"\"\"Check if Ollama server is running and accessible.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{cls.OLLAMA_API_URL}/api/tags\")\n",
    "            return response.status_code == 200\n",
    "        except requests.exceptions.RequestException:\n",
    "            return False\n",
    "\n",
    "    @classmethod\n",
    "    def _process_stream(cls, response: requests.Response) -> str:\n",
    "        \"\"\"Process streaming response from Ollama.\"\"\"\n",
    "        full_response = []\n",
    "        try:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    json_response = json.loads(line)\n",
    "                    if 'response' in json_response:\n",
    "                        full_response.append(json_response['response'])\n",
    "                        # Print progress without newline\n",
    "                        print('.', end='', flush=True)\n",
    "                    if json_response.get('done', False):\n",
    "                        print()  # New line after completion\n",
    "                        break\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to decode JSON from stream: {e}\")\n",
    "        \n",
    "        return ''.join(full_response).strip()\n",
    "\n",
    "    @classmethod\n",
    "    def translate(cls, text: str, source_lang: str = \"en\", target_lang: str = \"hi\", \n",
    "                 temperature: float = 0.7, timeout: int = None) -> str:\n",
    "        \"\"\"\n",
    "        Translate text using Ollama with streaming response handling.\n",
    "\n",
    "        Args:\n",
    "            text: Text to translate\n",
    "            source_lang: Source language code\n",
    "            target_lang: Target language code\n",
    "            temperature: Model temperature (0.0 to 1.0)\n",
    "            timeout: Request timeout in seconds (None for default)\n",
    "\n",
    "        Returns:\n",
    "            Translated text\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If Ollama server is not accessible\n",
    "            ValueError: If translation fails\n",
    "        \"\"\"\n",
    "        if not cls.check_status():\n",
    "            raise ConnectionError(\n",
    "                \"Cannot connect to Ollama server. Please ensure:\\n\"\n",
    "                \"1. Ollama is installed (https://ollama.ai/download)\\n\"\n",
    "                \"2. The Ollama service is running (run 'ollama serve' in terminal)\\n\"\n",
    "                \"3. You have pulled the required model (run 'ollama pull llama3.1')\"\n",
    "            )\n",
    "\n",
    "        prompt = (\n",
    "            f\"Translate the following {source_lang} text to {target_lang}. \"\n",
    "            f\"Provide only the direct translation without any additional comments or explanations.\\n\"\n",
    "            f\"Text: {text}\\n\"\n",
    "            \"Translation:\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            print(\"Starting translation\", end='', flush=True)\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{cls.OLLAMA_API_URL}/api/generate\",\n",
    "                json={\n",
    "                    \"model\": \"llama3.1:70b\",\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": True,\n",
    "                    \"temperature\": temperature,\n",
    "                },\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=timeout or cls.DEFAULT_TIMEOUT,\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            response.raise_for_status()\n",
    "            translated_text = cls._process_stream(response)\n",
    "\n",
    "            if not translated_text:\n",
    "                raise ValueError(\"Received empty translation from Ollama\")\n",
    "\n",
    "            return translated_text\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            raise ValueError(f\"Translation request timed out after {timeout or cls.DEFAULT_TIMEOUT} seconds\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise ValueError(f\"Translation request failed: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Unexpected error during translation: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    source_text = \"I'll go to Mumbai tomorrow\"\n",
    "    human_translation = \"मैं कल मुंबई जाऊंगा\"\n",
    "\n",
    "    try:\n",
    "        # First try machine translation\n",
    "        print(\"\\nPerforming machine translation...\")\n",
    "        machine_translation = OllamaTranslator.translate(\n",
    "            source_text,\n",
    "            source_lang=\"en\",\n",
    "            target_lang=\"hi\",\n",
    "            temperature=0.7  # Adjust temperature for balance of creativity and accuracy\n",
    "        )\n",
    "        print(f\"\\nMachine Translation: {machine_translation}\")\n",
    "\n",
    "        # Then evaluate both translations\n",
    "        print(\"\\nEvaluating translations...\")\n",
    "        evaluator = TranslationEvaluator()\n",
    "        \n",
    "        # Evaluate human translation\n",
    "        human_scores = evaluator.evaluate_translation(source_text, human_translation)\n",
    "        print(\"\\nHuman Translation Scores:\")\n",
    "        print(f\"BLEU Score: {human_scores.bleu:.4f}\")\n",
    "        print(f\"METEOR Score: {human_scores.meteor:.4f}\")\n",
    "        print(f\"BERT Similarity: {human_scores.bert_similarity:.4f}\")\n",
    "        print(f\"Aggregate Quality Score: {human_scores.aggregate:.4f}\")\n",
    "\n",
    "        # Evaluate machine translation\n",
    "        machine_scores = evaluator.evaluate_translation(source_text, machine_translation)\n",
    "        print(\"\\nMachine Translation Scores:\")\n",
    "        print(f\"BLEU Score: {machine_scores.bleu:.4f}\")\n",
    "        print(f\"METEOR Score: {machine_scores.meteor:.4f}\")\n",
    "        print(f\"BERT Similarity: {machine_scores.bert_similarity:.4f}\")\n",
    "        print(f\"Aggregate Quality Score: {machine_scores.aggregate:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
